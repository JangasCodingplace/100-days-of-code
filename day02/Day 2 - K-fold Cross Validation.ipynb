{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold Cross-Validation\n",
    "\n",
    "K-fold cross-validation is a technique for evaluating a machine learning model's performance. It involves splitting the data into k different subsets, training the model k times, each time using a different subset for evaluation and the remaining subsets for training. The final performance measure for the model is the average performance across all k folds. This technique helps to reduce bias and overfitting, and it provides a more robust estimate of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a schematic code example\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "X = df[['feature1', 'feature2', 'feature3']]\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into 10 folds\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "# Train and evaluate the model 10 times, each time using a different fold for evaluation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    model = train_model(X_train, y_train)\n",
    "    score = evaluate_model(model, X_test, y_test)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several techniques that can be uses to improve the performance of a model trained using k-fold cross-validation. Some of these techniques include:\n",
    "\n",
    "- **Using stratified k-fold cross-validation**: This involves creating splits where the proportions of different classes in the training and test sets are similar to the proportions in the original dataset. This can help to ensure that the model is trained and evaluated on a representative sample of the data.\n",
    "\n",
    "- **Using repeated k-fold cross-validation**: This involves running k-fold cross-validation multiple times and averaging the performance across all of the runs. This can help to reduce the variance in the performance estimates and give you a more reliable estimate of the model's performance.\n",
    "\n",
    "- **Using a larger value of k**: Increasing the value of k can help to reduce the variance in the performance estimates, but it can also increase the computation time. It is usually best to try a few different values of k and choose the one that gives the best trade-off between performance and computational cost.\n",
    "\n",
    "- **Using a different evaluation metric**: The performance of a model can depend on the choice of evaluation metric. It is often useful to try a few different metrics and see which one works best for your particular problem.\n",
    "\n",
    "- **Tuning the model's hyperparameters**: The performance of a model can also depend on the choice of hyperparameters. It is often useful to perform a grid search or a random search over the space of possible hyperparameters to find the combination that gives the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another idea can be to **variance the size of training data**. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create a list of k values to try\n",
    "k_values = [5, 10, 15, 20]\n",
    "\n",
    "for k in k_values:\n",
    "    # Create a KFold object with the current value of k\n",
    "    kf = KFold(n_splits=k)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        evaluate(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_You can then choose the value of k that gives the best performance on your dataset. Note that increasing the value of k will usually reduce the variance in the performance estimates, but it will also increase the computational cost. It is important to find the right balance between performance and computational cost._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example for using **KFolds** for an **NLP**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=16, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(lr=0.01), loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
