# 100DaysOfCode Diary

## Day 5 - OpenCV Contour Detection & Morphological Closing
- using the GrabCut algorithm is a computer vision algorithm that can be used to segment an image into foreground and background regions
- basic image processing operations, such as color conversion, blurring, edge detection, and dilation, can be performed using functions from the OpenCV library
- find and draw contours on an image with OpenCV

## Day 4 - Edge and Corner Detection
- Convert the image to grayscale using the cv2.cvtColor function and the cv2.COLOR_BGR2GRAY flag, if necessary.
- Use the cv2.Canny function to detect edges in the image, if desired.
- Use the cv2.cornerHarris function to detect corners in the image, or use one of the other corner detection algorithms available in OpenCV

## Day 3 - PyTesseract OCR
I provided information and examples of code that can be used to:

- Use Pytesseract to extract text from images.
- Preprocess images to improve the accuracy of OCR.
- Rotate images around a given angle using OpenCV or Pillow.


## Day 2 - K-Fold Cross-validation
- I discussed the concept of K-Fold Cross validation
- I've provided some kind of demosnippets with
    - basic KFold Cross Validation
    - KFold Cross Validation for various sizes
    - KFold Cross Validation to train an nlp


## Day 1 - Tokenization with NLTK
- I discussed the concept of tokenization in natural language processing (NLP), which is the process of splitting a string of text into individual tokens (words and punctuation marks).
- I've provided an example of a tokenization script in Python that uses regular expressions to split the input text into a list of tokens. I've also discussed how NLTK (Natural Language Toolkit) provides a number of built-in functions for tokenizing text.
- I showed how to add a docstring in numpy style to the tokenize function, and provided some test cases that can be used to test the function's behavior.
- wrote some unit tests
